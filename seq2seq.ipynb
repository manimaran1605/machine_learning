{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5620a37-0ad1-47df-912b-c72d0ecc9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bd8f18-ac67-49e1-b526-1716b668d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"good morning\"\n",
    "target_text = \"\\tguten morgen\\n\"  # \\t = start, \\n = end for training convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ea0557-f4af-40a3-beac-d74fa25b086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = sorted(list(set(input_text)))\n",
    "target_chars = sorted(list(set(target_text)))\n",
    "num_encoder_tokens = len(input_chars)\n",
    "num_decoder_tokens = len(target_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1670a040-3e7b-449a-9a55-ea1daefe451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'd', 'g', 'i', 'm', 'n', 'o', 'r']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ba9625-c944-4657-a357-2b6fd92a3cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t', '\\n', ' ', 'e', 'g', 'm', 'n', 'o', 'r', 't', 'u']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f291d2fb-7ebe-4184-a4d9-697c58fb6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = len(input_text)\n",
    "max_decoder_seq_length = len(target_text)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_chars)])\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5defb819-e98e-44a0-aa76-967238ab4bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0, 'd': 1, 'g': 2, 'i': 3, 'm': 4, 'n': 5, 'o': 6, 'r': 7}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7ae8a1-6b3d-4539-83ae-eff8c79e616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " 'e': 3,\n",
       " 'g': 4,\n",
       " 'm': 5,\n",
       " 'n': 6,\n",
       " 'o': 7,\n",
       " 'r': 8,\n",
       " 't': 9,\n",
       " 'u': 10}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d5511a-5caa-4780-8897-c803260cb9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\t',\n",
       " 1: '\\n',\n",
       " 2: ' ',\n",
       " 3: 'e',\n",
       " 4: 'g',\n",
       " 5: 'm',\n",
       " 6: 'n',\n",
       " 7: 'o',\n",
       " 8: 'r',\n",
       " 9: 't',\n",
       " 10: 'u'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_target_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c4e4fd-5ef8-49df-bf17-c3fb03d0d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((1, max_encoder_seq_length), dtype='int32')\n",
    "decoder_input_data = np.zeros((1, max_decoder_seq_length), dtype='int32')\n",
    "decoder_target_data = np.zeros((1, max_decoder_seq_length, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8c535b4-a6f0-4d3c-a33b-e66ab9aa8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, char in enumerate(input_text):\n",
    "    encoder_input_data[0, t] = input_token_index[char]\n",
    "\n",
    "for t, char in enumerate(target_text):\n",
    "    decoder_input_data[0, t] = target_token_index[char]\n",
    "    if t > 0:\n",
    "        decoder_target_data[0, t - 1, target_token_index[char]] = 1.0\n",
    "\n",
    "# Define model\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "939b29ac-47a7-4d7a-9e94-914d5bd91cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 6, 6, 1, 0, 4, 6, 7, 5, 3, 5, 2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data #good morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf40f4e-a49f-4520-bbfe-8dabaaf1c6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data #one hot encoding of \"guten morgen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71b3b195-2d7d-46c1-9cf3-701623ad6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(input_dim=num_encoder_tokens, output_dim=latent_dim)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb) \n",
    "#USING LSTM, you can use RNN, but for large sentences, you may face vanishing gradients\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eeb7c4de-04f1-4084-8b33-c613803cf23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(input_dim=num_decoder_tokens, output_dim=latent_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2421a041-1bef-40c7-99e9-677f639cee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d87b5c17f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=1, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf7afff6-6a96-47a4-8421-5eb871d35836",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "645e59c6-aeef-4d93-9e10-99d671da1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a714adc1-572a-447d-9fae-88b8e798d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_emb2 = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
    "    dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efe6241f-9467-43c0-85a6-e367b539bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Input: good morning\n",
      "Output: guten morgee\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_token_index['\\t']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Prepare input for inference\n",
    "test_input = np.zeros((1, max_encoder_seq_length), dtype='int32')\n",
    "for t, char in enumerate(input_text):\n",
    "    test_input[0, t] = input_token_index[char]\n",
    "\n",
    "# Translate\n",
    "translated = decode_sequence(test_input)\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Output: {translated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
